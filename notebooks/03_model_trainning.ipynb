{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ccb1c99",
   "metadata": {},
   "source": [
    "# MODELOS DE ENTRENAMIENTO DE MACHINE LEARNING    \n",
    "\n",
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e298d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_sample_data\n",
    "\n",
    "df_sample = get_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89102bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_engineerings import create_pattern_features\n",
    "\n",
    "# Aplicar  \n",
    "df = create_pattern_features(df_sample)\n",
    "\n",
    "# An√°lisis de patrones\n",
    "pattern_analysis = df.groupby(['off_hours', 'suspicious_frequency'])['isFraud'].mean()\n",
    "print(\"An√°lisis de patrones sospechosos:\")\n",
    "print(pattern_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660519ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_engineerings import encode_categorical_features\n",
    "\n",
    "# Aplicar\n",
    "df_encode, label_encoder = encode_categorical_features(df)\n",
    "print(\"Variables categ√≥ricas codificadas exitosamente\")\n",
    "print(df_encode[[col for col in df_encode.columns if 'hour' in col]].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a268f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression para detecci√≥n de fraude\n",
    "from src.feature_engineerings import  scale_features\n",
    "from src.feature_engineerings import  select_important_features\n",
    "from src.models import logistic_regression\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar y escalar dataset\n",
    "X_train, X_test, y_train, y_test, scaler = scale_features(df_encode)\n",
    "\n",
    "feature_importance, selected_features, selector = select_important_features(X_train, y_train)\n",
    "print(\"Caracter√≠sticas seleccionadas:\")\n",
    "#print(selected_features)\n",
    "\n",
    "# Crear dataset final optimizado\n",
    "X_train_final = X_train[selected_features]\n",
    "X_test_final  = X_test[selected_features]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr_model = logistic_regression(X_train_final, y_train, X_test_final, y_test)\n",
    "\n",
    "print(\"Modelo de regresi√≥n log√≠stica entrenado y evaluado.\")\n",
    "#print(\"Caracter√≠sticas seleccionadas:\", lr_model)  # Asumiendo que el cuarto elemento es 'selected_features'\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(selected_features.tolist())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091d526",
   "metadata": {},
   "source": [
    "NOTA: LA REGRESION LOGISTICA TIENE UN RECALL ALTISIMO PERO CON MUCHOS FALSOS POSITIVOS TOCARIA USAR TECNICAS DE BALANCEO DEL DATASET COMO SMOTE PARA LOGRAR UN RESULTADO CON MAS PRESICION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fed246",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Random Forest es un modelo de aprendizaje supervisado basado en ensembles de √°rboles de decisi√≥n. Combina m√∫ltiples √°rboles para reducir la varianza y mejorar la generalizaci√≥n. Usa bootstrap aggregation (bagging) y selecciona aleatoriamente subconjuntos de features en cada √°rbol.\n",
    "\n",
    "üß™ Ideal para:\n",
    "    - Clasificaci√≥n con datos tabulares\n",
    "    - Manejo de overfitting\n",
    "    - Datasets desequilibrados con class_weight='balanced'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest para detecci√≥n de fraude\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar modelo\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features = 'sqrt',\n",
    "    min_samples_leaf = 4,\n",
    "    min_samples_split = 2,\n",
    "    max_depth=12,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "print(\"Entrenando Random Forest...\")\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Evaluar\n",
    "y_pred = rf_model.predict(X_test_final)\n",
    "y_prob = rf_model.predict_proba(X_test_final)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"Resultados:\")\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train_final.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top features importantes:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cce554",
   "metadata": {},
   "source": [
    "# XGBoost \n",
    "\n",
    "(eXtreme Gradient Boosting) es una implementaci√≥n optimizada de gradient boosting. Aprende secuencialmente minimizando una funci√≥n de p√©rdida con regularizaci√≥n L1/L2 para prevenir overfitting. Usa √°rboles de decisi√≥n como base learners.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f51315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost para m√°ximo rendimiento\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Calcular peso para balancear clases\n",
    "normal_count = len(y_train[y_train==0])\n",
    "fraud_count = len(y_train[y_train==1])\n",
    "pos_weight = normal_count / fraud_count\n",
    "\n",
    "# Configurar modelo\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    subsample = 0.8,\n",
    "    reg_alpha = 0.5,\n",
    "    reg_lambda = 2.0,\n",
    "    gamma = 0,\n",
    "    colsample_bytree = 1.0,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=pos_weight,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "print(\"Entrenando XGBoost...\")\n",
    "xgb_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Evaluar\n",
    "y_pred = xgb_model.predict(X_test_final)\n",
    "# üí° Nuevo threshold (por ejemplo, 0.4 en lugar de 0.5)\n",
    "threshold = 0.3  # <-- Aqu√≠ puedes ir probando: 0.3, 0.4, 0.6, etc.\n",
    "y_pred_custom = (y_prob > threshold).astype(int)\n",
    "\n",
    "# Evaluaci√≥n con el nuevo threshold\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"Resultados XGBoost con threshold {threshold}:\")\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(confusion_matrix(y_test, y_pred_custom))\n",
    "print(classification_report(y_test, y_pred_custom))\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"Modelo XGBoost entrenado y evaluado.\")\n",
    "print(\"Caracter√≠sticas seleccionadas:\")\n",
    "print(xgb_model.feature_names_in_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import joblib\n",
    "\n",
    "# Guardar modelo entrenado\n",
    "joblib.dump(xgb_model, 'modelo_xgboost_fraude.pkl')\n",
    "\n",
    "# Guardar scaler y features seleccionadas si los usaste\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(selected_features, 'features_seleccionadas.pkl')\n",
    "\n",
    "# Guardar threshold\n",
    "with open('threshold.txt', 'w') as f:\n",
    "    f.write(str(0.3))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# === 1. Guardar modelo entrenado ===\n",
    "joblib.dump(xgb_model, 'modelo_xgboost_fraude.pkl')\n",
    "\n",
    "# === 2. Guardar scaler usado para normalizaci√≥n ===\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# === 3. Guardar selector de features importantes ===\n",
    "joblib.dump(selector, 'selector_kbest.pkl')\n",
    "\n",
    "# === 4. Guardar nombres de las features seleccionadas (para verificar columnas en producci√≥n) ===\n",
    "joblib.dump(selected_features, 'features_seleccionadas.pkl')\n",
    "\n",
    "joblib.dump(X_train, 'X_train_columns.pkl')  # Guarda las columnas en orden correcto\n",
    "\n",
    "\n",
    "# === 5. Guardar threshold personalizado (si tu modelo usa un umbral ajustado para clasificar fraude) ===\n",
    "with open('threshold.txt', 'w') as f:\n",
    "    f.write(str(0.3))  # Cambi√° 0.3 por tu valor real si lo ten√©s ajustado\n",
    "\n",
    "print(\"‚úÖ Todo fue guardado exitosamente para producci√≥n.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dded9b",
   "metadata": {},
   "source": [
    "## DESPLIEGUE ANTIFRAUDE MODELO XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# === Cargar componentes entrenados ===\n",
    "model = joblib.load('modelo_xgboost_fraude.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "selector = joblib.load('selector_kbest.pkl')\n",
    "X_train_col = joblib.load('X_train_columns.pkl')  # Necesit√°s guardar esto en tu entrenamiento\n",
    "\n",
    "# === Crear un diccionario con la estructura completa ===\n",
    "data_prueba_dict = {\n",
    "\n",
    "    'step': 250,               # Paso del tiempo alto (transacci√≥n tard√≠a en el d√≠a)\n",
    "    'amount': 9800.0,          # Monto alto y cerca de un umbral t√≠pico de reporte\n",
    "    'oldbalanceOrg': 9800.0,   # El cliente transfiere casi todo su saldo\n",
    "    'newbalanceOrig': 0.0,     # Queda sin saldo\n",
    "    'oldbalanceDest': 0.0,     # Cuenta destino vac√≠a\n",
    "    'newbalanceDest': 9800.0,  # Recibe todo el dinero\n",
    "    'hour_of_day': 3,          # De madrugada\n",
    "    'off_hours': 1,            # Horario fuera de lo normal\n",
    "    'day_of_week': 0,          # Lunes\n",
    "    'weekend_activity': 0,     # No es fin de semana\n",
    "    'amount_frequency': 120,   # Monto repetido muchas veces\n",
    "    'suspicious_frequency': 1, # Actividad sospechosa\n",
    "    'structured_amount': 1,    # Monto ‚Äúestructurado‚Äù cerca de l√≠mites\n",
    "    'dest_diversity': 20,      # Transfiere a muchos destinos\n",
    "    'high_dest_diversity': 1,  # Fan-out alto\n",
    "    'type_encoded': 4,         # TRANSFER (alto riesgo)\n",
    "    'type_CASH_IN': 0,\n",
    "    'type_CASH_OUT': 0,\n",
    "    'type_DEBIT': 0,\n",
    "    'type_PAYMENT': 0,\n",
    "    'type_TRANSFER': 1,        # Es una transferencia\n",
    "    'type_fraud_rate': 0.5,    # Alta tasa hist√≥rica de fraude en este tipo\n",
    "    'hour_sin': -0.99,\n",
    "    'hour_cos': 0.14\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Convertir a DataFrame y alinear columnas ===\n",
    "data_prueba = pd.DataFrame([data_prueba_dict])\n",
    "\n",
    "\n",
    "# Reordenar columnas exactamente como en el entrenamiento\n",
    "data_prueba = data_prueba[X_train_col.columns]  # OJO: necesitas haber guardado X_train.columns\n",
    "#print(\"Columnas que espera el scaler:\", list(X_train.columns))\n",
    "#print(\"Columnas que le estoy pasando:\", list(data_prueba.columns))\n",
    "\n",
    "data_scaled = scaler.transform(data_prueba)\n",
    "\n",
    "# === Selecci√≥n de features importantes ===\n",
    "data_selected = selector.transform(data_scaled)\n",
    "\n",
    "# === Predicci√≥n ===\n",
    "prediccion = model.predict(data_selected)\n",
    "probabilidad = model.predict_proba(data_selected)[0][1]\n",
    "\n",
    "# === Mostrar resultado ===\n",
    "print(\"¬øEs fraude?:\", \"‚úÖ S√ç\" if prediccion[0] == 1 else \"‚ùå NO\")\n",
    "print(f\"Probabilidad de fraude: {probabilidad:.2%}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
